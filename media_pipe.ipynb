{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Estimación de Poses con IA utilizando Python y MediaPipe\n",
    "+ Proyecto de Seguimiento de Gimnasio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp# esto nos da las soluciones\n",
    "import numpy as np\n",
    "mp_dibujo= mp.solutions.drawing_utils\n",
    "mp_pose= mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el feed para nuestra webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CODIGO BASE QUE REUTILIZAREMOS MAS TARDE \n",
    "#feed de video\n",
    "cap= cv2.VideoCapture(0)# este numero representa mi camara\n",
    "while cap.isOpened():\n",
    "  ret,frame=cap.read()# esto nos guarda el feed de nuestra webcam en estas variables \n",
    "  cv2.imshow('Mediapipe Feed', frame)# aca mostramos la imagen de la webcam \n",
    "\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):# esto chequea si le damos a \"q\" o cerramos la ventana y rompe el loop \n",
    "    break\n",
    "cap.release()# liveramos nuestraaa webcam \n",
    "cv2.destroyAllWindows()#cierra la ventana \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinar las Uniones que vamos a utilizar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999691843986511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esta es la forma de extraer y mapear los puntos de referencia 'landarks'\n",
    "#vamos a usarlo en el codigo final\n",
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.65621895\n",
       "y: 0.8706873\n",
       "z: -0.08311059\n",
       "visibility: 0.97787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular los Angulos:\n",
    "\n",
    "Creamos una función que calcule ángulos y la utilizaremos en el hombro, codo y muñeca para calcular el ángulo del brazo contraído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_angulo(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5285757184028625, 0.7837801575660706],\n",
       " [0.6449593305587769, 0.8617578744888306],\n",
       " [0.7381910681724548, 0.8755338191986084])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtenemos los valores x e y:\n",
    "Hombro=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "Codo=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "Muneca= [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "Hombro,Codo,Muneca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.5828981324397"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_angulo(Hombro,Codo,Muneca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#UTILIZAMOS EL CODIGO BASE ANTERIOR\n",
    "#IMPORTANTE PARA CORRER ESTE CODIGO PRIMERO DEBES IMPORTAR Y CREAR LA FUNCION \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Contador de curls\n",
    "counter=0\n",
    "stage=None\n",
    "\n",
    "#Configuramos la instancia de mediapipe\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5)as pose:#acedemos al modelo de estimacion Pose y le especificamos las metricasa de confianza de la camaara y acedemos a la variable como pose\n",
    "  while cap.isOpened():\n",
    "      ret, frame = cap.read()\n",
    "      # recololear la imagen porque cuando la pasemos a mediapipe la queremos en RGB por defaul esta en BGR\n",
    "      image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)# tomamos el feed de laa camara y lo reorgaanizamos\n",
    "      image.flags.writeable=False#ahorramos memoria\n",
    "      # realizar la deteccion \n",
    "      results=pose.process(image)# guardamos la detecciones en la variable resultados \n",
    "      image.flags.writeable=True\n",
    "      # recoloreamos a BGR\n",
    "      image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)# volvemos a a recolorear a BGR parA renderizarrla en opencv que la quiere en BGR\n",
    "      # Extraer  puntos de referencia\n",
    "      try:\n",
    "          landmarks = results.pose_landmarks.landmark\n",
    "          \n",
    "          #Obtener las coordenadas\n",
    "          Hombro=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "          Codo=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "          Muneca= [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "          #Calcular el Angulo CON 3 PUNTOS DE REFERENCIA \n",
    "          angulo=calcular_angulo(Hombro,Codo,Muneca)\n",
    "          #Visualizar el angulo \n",
    "          cv2.putText(image,str(angulo),\n",
    "                      tuple(np.multiply(Codo,[640,480]).astype(int)),# pasamos la imagen de nuestra camara, el angulo y determinamos donde estmos posicionados teniendo en cuenta la camara \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "      \n",
    "      #Logica del contador de Curls \n",
    "          if angulo > 160:\n",
    "              stage = \"down\"\n",
    "          if angulo < 30 and stage =='down':\n",
    "              stage=\"up\"\n",
    "              counter +=1\n",
    "              print(counter)\n",
    "      \n",
    "      except:\n",
    "          pass\n",
    "      #Renderizar el contador \n",
    "      #Configurar caja \n",
    "      cv2.rectangle(image, (0,0), (260,73), (245,117,16), -1)\n",
    "      #Data de las Rep\n",
    "      cv2.putText(image, 'REPS', (15,12), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "      cv2.putText(image, str(counter), \n",
    "                  (10,60), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "      # Posicion del brazo \n",
    "      cv2.putText(image, 'ESTADO', (65,12), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "      cv2.putText(image, stage, \n",
    "                  (100,60), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "      \n",
    "      # Renderizar las Detecciones\n",
    "      mp_dibujo.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                               mp_dibujo.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
    "                               mp_dibujo.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2)\n",
    "                               )#Con esto dibujamos nuestras detecciones a nuestra imagen y personalizamos \n",
    "      \n",
    "      cv2.imshow('Mediapipe Feed', image)\n",
    "      \n",
    "      if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "          break  \n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
